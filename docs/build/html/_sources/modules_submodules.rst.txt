Modules and submodules
======================

Here is reported the list of each implemented module and submodule the relative documentation

.. _DatasetManager:

DatasetManager
--------------

Implemented dataset managers are expected to manage the dataset acquisition, the tokenization and the formatting of a partitioned dataset. 

Commonly a dataset is partitioned in :code:`train`, :code:`validation` and :code:`test`

A dataset managers is expected to have the following submodules:

.. _dataset_reader:

:doc:`dataset_reader <dataset_readers>`:
    a module that read the dataset from the actual dataset file

.. _dataset_tokenizer:

:doc:`dataset_tokenizer <dataset_tokenizers>`:
    a module that tokenize the acquired dataset

.. _dataset:

:doc:`dataset <datasets>`:
    a module that is a subclass of :code:`torch.utils.data.Dataset` and has to prepare the tokenized dataset to be used in a :code:`torch.utils.data.Dataloader` defining the :code:`batch`


.. _EntityTypingNetwork:

Entity Typing Network
---------------------

Implemented entity typing networks are expected to produce a logit for each type for each input sentence.

An Entity Typing Network receives input sentences through a :code:`batch` generated by the :code:`dataset` submodule

To be instantiated an Entity Typing Network always needs a name, some parameters in the :code:`yaml` configuration file under the key :code:`model` and the number of types, given by the :ref:`Dataset Manager <DatasetManager>`

An Entity Typing Network is expected to have the following submodules:

.. _encoder:

:doc:`encoder <encoders>`:
    A module that encodes an input sentence starting from a tokenized version inside the :code:`batch`

    Commonly an encoder takes in input a tokenized sentence (a tensor of integers) and return a tensor with some representation of the input tokenized sentence

.. _type_encoder:

:doc:`type encoder <type_encoders>`:
    A module that encodes the types starting from their tokenized version (an id or a list of id) inside the :code:`batch`

    Commonly a type encoder takes in input a type id or a list of type ids and return a tensor with some representation of the type (or the types)

.. _input_projector:

:doc:`input projector <input_projectors>`:
    A module that projects the encoded input in a common space, where types are placed. 
    
    The input projector is needed since the encoder has not to be aware of the type representation space (we assume an encoder encodes a sentence in a space with fixed dimension, e.g., 768 for :code:`BertBase`). We think that this solution helps in building simple encoder modules

    Commonly a input projector takes in input the encoded input (returned from the :ref:`encoder submodule <encoder>`) and project it in the type representation space (defined by the :ref:`type encoder <type_encoder>`)

Implemented Modules
-------------------

.. toctree::
    
    dataset_managers
    entity_typing_networks

Implemented Submodules
----------------------

.. toctree::
    
    dataset_readers
    dataset_tokenizers
    datasets
    encoders
    type_encoders
    input_projectors

